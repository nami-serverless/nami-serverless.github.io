---
layout: post
title: Introducing Nami

---

## Introduction {#introduction}
---

When events occur in batches, a wave of webhooks may overwhelm consumers, resulting in dropped data. Always-on systems must be provisioned to handle worst-case scenarios, however, this is inefficient as these resources will be idling most of the time. What is needed is an efficient and easily deployable architecture for consuming webhooks at scale.

Nami provides a simple interface for deploying this type of architecture to consume webhooks. It relies on the elasticity of serverless systems to handle bursty webhook traffic. The framework abstracts away the complexities of cloud infrastructure and effort required to deploy, configure, and choreograph all of the services that make up the Nami framework.

<br />

## Event-driven architecture {#eda}
---

Webhooks represent an event-driven approach to development. They allow applications to take in data about events as they happen, trading control of data flow for event-driven update and asynchronicity. Nami’s event-driven architecture embraces this trade-off.

Since the introduction of web communication protocols like HTTP in the 1980s, the dominant paradigm for communication between systems is a client-server request-driven architecture where a client, or many clients, make a request to a server. The client’s request may either be getting information from the server, or updating information on the server. In either case, the server returns a response acknowledging the request, optionally including data that the client requested. This request-response process is a synchronous method of communication in that the client must wait for the server to return a response before continuing execution.

In an event-driven architecture (EDA), events represent changes in state that have already occurred. “An event is an object or message that indicates something has happened;” it holds information about that happening, but does not contain any logic itself (1). Rather than requesting for work to be done, the consumer responds to events that are announced after they have occurred. The EDA paradigm is asynchronous in that a caller is never sitting idle, waiting for a response to be returned. In an asynchronous, event-driven model, the dichotomy of client and server loses the meaning it has in the request-driven context, so we can instead use terms such as event producer (server sending the event notification) and event consumer (server receiving the event notification).

![EDA example](../assets/eda.png)

<br />

## Webhooks {#webhooks}
---

One way that the shift towards an event-driven paradigm manifests is in the use of webhooks. Webhooks are a mechanism for one system to notify another system of an event that has occurred.

Before webhooks became a popular way to move data, polling techniques were commonly used to retrieve event information from services. If your app needed information from a service, you needed to continually poll that service with HTTP requests at a certain time interval to see if they had updated information for you.

![Polling an API for Data](../assets/image12.png)

If that service does not have any updates, the resources used to contact the service were wasted. What if the service entered a state where they ceased to have updates for you? You would just be continually polling and wasting resources. Webhooks turn this situation around: “don’t call us, we’ll call you.”

When a particular event occurs and triggers a webhook, the producer, or webhook sender, calls the receiver by making an HTTP request to the URL configured for the webhook.

![webhook and event](../assets/image9.png)

Webhook data is most commonly sent via a POST request with the payload included in the request body. Webhooks can be sent as several different content types, including JSON, form-data, or XML. Once the request is received by the webhook consumer, a status 200 response is sent back to the webhook producer to let them know that the API endpoint is still listening and the message was successfully received.

Example webhook payload for Shopify inventory item created event

![webhook and event](../assets/image11.png)

A common use case for Webhooks is for real time event notification. Systems that generate a lot of events can quickly ramp up the webhook traffic to the destination. If webhook traffic grows consistently it is relatively easy to accommodate the extra load with additional infrastructure. More difficult though, is inconsistent, bursty traffic.

<br />

### Manual solution
---

To handle these occasional spikes in traffic, the webhook consumer app could provision additional infrastructure to handle the extra traffic. However, there are a few drawbacks to this approach. Servers are expensive and require ongoing maintenance. Further, provisioning infrastructure that will sit idle and unused much of the time is an inefficient use of resources, especially for consumers receiving webhooks in volatile patterns.

![servers to handle webhook traffic](../assets/image21.png)

This also makes the core application, sharing the same infrastructure, more vulnerable to downtime caused by problems with handling webhooks. Additionally, by nature of being event driven, the consumer cannot control the flow of data. If the flow of a webhook comes in like a firehose and generates more traffic than the application can handle, the result will be an unintentional denial-of-service (DoS) attack. This is like a crowd of people blocking the entry door of a business, making it more difficult for legitimate customers to enter, or denying them service (9).

Considering the challenges with using onsite infrastructure to handle webhooks at scale, these types of use cases fit well with auto-scaling compute services like AWS Lambda, AWS’ Function as a Service (FaaS) platform. The elastic scaling capability of Lambda allows for compute resources to scale up and down on demand.

<br />

## Serverless Computing | FaaS {#serverless}
---

Before we look more closely at AWS Lambdas, let’s take a step back and look at severless as a whole.

Serverless computing is characterized both by the absence of having to manage dedicated servers or the deployment environment, as well as the ability to bring an application up and down in response to an event. virtual machines or having to . This is in contrast to a central server model, where flow, control, and security are typically all orchestrated by the central server.  This is in contrast to IaaS and PaaS, which are platforms not designed to be brought online only to handle a brief execution.  where the user has more control over such resources. The serverless model focuses on choreography of the individual services rather than orchestration by a central authority. Choreography makes the system more flexible, amenable to change, and have better division of concerns. The tradeoff is added complexity and monitoring (10).

Functions as a Service, or FaaS, is a type of serverless computing offered by multiple cloud platforms, with popular services such as AWS Lambda, Google Cloud Functions, and Microsoft Azure Functions. In a FaaS environment, function code is uploaded to the cloud platform, which then deploys a container provisioned with the function code and other required resources necessary for the function to be successfully executed. With AWS Lambda functions, scaling is automatic, elastic to meet the demands of incoming requests, and fully managed by the provider . Compute containers are spun up only when needed, and then shut down as soon as the function has finished execution. The customer pays only for the actual execution time of the function , which can be a significant cost-savings over an always-on server.

Considering these benefits of a serverless solution, it’s clear that a managed server infrastructure wastes resources by requiring the provisioning of enough servers to handle bursty webhook traffic generated by batched events. Use cases consuming webhooks with such traffic patterns, that need only to perform a brief, simple acknowledgement of the request, lend themselves well to a serverless infrastructure.

<br />

## Real World Examples {#real-world-examples}
---

Two examples of existing solutions that solve this problem of webhooks arriving in bursty, unpredictable traffic patterns serve as a general guide for using a primarily serverless infrastructure to solve this problem.

### Example 1
---
Jira, a project management software which tracks issues and bugs for software development teams offers webhooks that another internal service uses to automate that issue-tracking. The webhooks generally come in a consistent, steady flow which the system infrastructure can easily accommodate. However, at times, customers update or delete issues in bulk, causing spikes to the service’s incoming webhook traffic. Thousands of webhook requests can arrive in very short time periods. The webhook data needs to be processed at high-speed and then written to a data store without being dropped along the way. To handle this bursty traffic, they set up an AWS services architecture that is able to auto-scale appropriately to the number of incoming requests, and then slow the velocity of the data so as not to overwhelm the relational database where payloads remain for further processing.

![jira](../assets/image16.png)

### Example 2
---
Shopify ecommerce platform offers services to online shops including tools for payment, marketing, shipping, and customer engagement. Rewind uses Shopify webhooks to provide automated backups of shops' data in "real-time" as customers make changes to their store’s products. This webhook traffic can sometimes burst because customers can generate tens of thousands of webhooks instantly - for example, when a new inventory is imported (a "products/update" hook is posted) during a nightly bulk operation. Their solution implements a scalable architecture on AWS, utilizing a message queue to throttle the velocity of the webhook messages before they hit the data store.

![rewind](../assets/image23.png)

<br />

## Need for a framework {#need-for-a-framework}
---

The engineers at Jira and Rewind spent a not insignificant amount of time setting up cloud services to handle their webhook traffic.  While a serverless infrastructure offers a solution to this problem of bursty webhook traffic, another problem still remains: Developers should not have to spend their time setting up this scaffolding and learning the intricacies and gotchas of a cloud platform just to scale for webhooks. A framework is needed so that system provisioning and deployment process can be streamlined

Working within cloud platforms is not a trivial endeavor. Even though AWS is the current industry leader in cloud computing, the complexity of AWS and its multitude of services means that the learning curve is steep to perform even simple tasks. Choreographing individual services to communicate and work in a coordinated way only compounds this problem. Each individual task performed on AWS might appear simple, however, they are usually comprised of several microtasks.

![table](../assets/table.png)

Nami solves this complexity problem with a simple command line interface; making it easy to deploy an AWS endpoint and quickly stand up a pipeline for webhook data that scales up and down to match traffic patterns without any intervention required from the user. Nami enables the user to deploy with one command what would take over 50 separate AWS CLI or SDK commands to deploy, configure, and connect each piece of infrastructure. This pipeline, built using AWS services, serves to receive, acknowledge, process, and store payloads received from webhooks.

![deploy_gif](../assets/nami_deploy.gif)

<br />

## Commands {#commands}
---

The following commands are used to deploy and interact with the Nami framework.

![deploy_command](../assets/deploy_command.png)

Running the deploy command sets up a new instance of the framework, including the following services:
- API Gateway endpoint unique to the <name> of your deployment,
- A pre-queue Lambda,
- A post-queue Lambda,
- An SQS queue,
- A Dead Letter Queue (DLQ), and
- an EC2 instance provisioned with MongoDB deployed via Docker
- Security groups for the post-queue Lambda and EC2 instance

![create_command](../assets/create_command.png)

Should the user want to add their own logic to the pre-queue and post-queue Lambda files before an instance of the framework gets deployed, they can run the create command. When a user executes the create command, two directories are created; one with each of the pre-queue and post-queue Lambda files with the same logic as if they had executed the deploy command.

![destroy_command](../assets/destroy_command.png)

The `destroy` command will delete all of the resources unique to a particular <name>, including the API Gateway resource and endpoint (but not API Gateway itself), the two Lambda functions, the SQS queue and DLQ, and terminate the EC2 instance. The EBS volume will persist in case the user has not retrieved all of their data.

![list_command](../assets/list_command.png)

The user can run the `list` command to see a full list of active API endpoints along with which resource name they were created under.

![help_command](../assets/help_command.png)

The user can run the `help` command to see documentation for all nami commands.

<br />

## How it works {#how-it-works}
---

![nami_system_diagram](../assets/nami_system.png)

When the event producer makes a request, the API gateway is the first port of call. It accepts the request containing webhook event data, which is encapsulated as an event object, and triggers invocation of the pre-queue Lambda.

The function pushes the event data onto the SQS queue and responds to the webhook producer’s POST request with a 200 status code if the function execution is successful.

As event data messages enter the queue, this triggers invocation of the post-queue lambda, which consumes those messages at a stable rate.

The post-queue Lambda then opens a connection to the database, a MongoDB image deployed with Docker on EC2. The function code retrieves the payload from the event object and writes it to the database.

A successful write to the database causes the queue to delete the message. This process repeats until the queue is empty. If the write is unsuccessful, the queue will retry sending the message up to 5 times before sending it to a Dead Letter Queue (DLQ).

The event data is stored on an EBS volume, AWS’ magnetic disk storage, which the MongoDB image uses as persistent storage instead of the ephemeral storage of the Docker environment or EC2 instance itself.is mapped to the instance’s instance storage. The data is now at rest in the database and ready for the user to retrieve.

<br />

## Nami Framework Design Decisions {#nami-framework-design-decisions}
---

As we worked through engineering our solution, we considered tradeoffs to maximize scalability and minimize complexity for the user. Here we explore some of those tradeoffs and the design decisions we made during development.

<br />

### Receiving and Acknowledging Webhook Data
---

<br />

#### Unreserved Concurrency for Maximum Scaling
---

AWS Lambda functions are an ideal tool with which to handle bursty traffic. Lambda functions can be invoked concurrently, where concurrent executions are the number of executions of a function’s code that are happening in parallel at any given time. Nami deploys two separate Lambda functions; a pre-queue Lambda and a post-queue Lambda. The pre-queue Lambda serves as the webhook receiver, the front facing function that ingests incoming webhook traffic. This core part of the architecture should scale to its limit since we are relying on its elasticity to handle and respond to bursts of incoming requests. To enable this level of scaling, we configure the pre-queue Lambda function to use the AWS account level unreserved concurrency limit of 1000 concurrent Lambda functions. Although this number declines slightly after the post-queue Lambda is created and allocated 5 concurrent executions of its own, utilizing the unreserved concurrency pool will give the pre-queue Lambda function the most room for scaling compared to reserving a specific function concurrency.

![lambda_scaling](../assets/lambda_scaling.png)

<br />

#### Execution Logic
---

In an event driven model, the event producer and consumer should not be aware of one anothers implementation. The consumer should not block the producer while processing the data. Instead, the consumer should simply receive the data, send it on for further processing, and then acknowledge receipt. Therefore, the function only receives the payload, enqueues it, and returns a 200 success response to the sender. The user can also optionally add authentication logic to the function handler. Any kind of webhook event data processing is delegated to post-queue lambda which reads the webhook payload from the Nami deployed queue.  

<br />

#### Memory Allocation
---

During load testing, we aimed for a performance of around 5,000 requests per second (RPS) to compare with real world examples that solved bursty webhook traffic issues using a serverless architecture similar to Nami. We had found that increasing the function memory size to 256MB from a default of 128MB resulted in the best response times for this scenario, optimizing scaling power. Provisioning a Lambda function with higher memory has a direct correlation with longer cold start times during the container initialization process. In this case, however, function execution times were still well within both tolerable levels for an expected webhook response time as well as the default function timeout limit of 3 seconds. When testing our system to determine how memory size would impact execution duration, we observed that increasing beyond 256MB yielded diminishing returns. With this decision, we traded lower cost of minimum memory and shorter cold start times for lower execution duration and greater scaling capacity. If a Nami user finds that a different memory setting is optimal for their customized implementation, they can easily adjust this setting from the AWS Lambda console.

![api_gateway](../assets/api_gateway.png)

<br />

#### Multiple Framework Instances
---

We chose to support multiple instances of the framework where each instance is unique to an individual webhook provider. Rather than deploying a new API Gateway endpoint for each instance, we consolidate user endpoints as child resources under the parent or root resource of the API Gateway.. Setting up the API Gateway in this manner takes care not to burden the limit of individual API Gateways allowed on an account. Each time the user executes the deploy command to generate an additional API endpoint, a new resource that accepts HTTP POST requests is created on the API Gateway. Each resource represents a unique API endpoint by replacing the end of the path with the specified resource name across a consistent host.

<br />

### Message Queue
---

We connect the Lambda receiving webhook requests to the data store via an SQS queue as message broker, reinforcing our design in several ways.

<br />

#### Evening out traffic spikes
---

Because the queue allows us to scale the producer and consumer separately, and allows us to have multiple consumer Lambdas, we have a different capacity for throughput on each side. When the producer is producing messages faster that the consumer can handle, the queue can buffer the messages until the consumer is ready to receive them.

An AWS SQS message queue is deployed in between the Lambda functions  as a means to throttle the message flow, controlling the distribution of webhook data  

![capacity](../assets/capacity.png)

Another downstream resource which could become overwhelmed without the throttling mechanism of the queue is the data store itself. Each second, thousands of consumer Lambda functions could be attempting connections to the EC2 instance, which will quickly become overloaded. While a larger instance size with more RAM could be used to support more incoming connections, we chose to keep costs lower with a smaller instance size as the queue’s throttling action is sufficient.

<br />

#### Decoupling
---

Similar to the way that the use of webhooks decouples event producer from event consumer, using the SQS queue at the center of our architecture decouples the pre-queue Lambda sending the message from the post-queue Lambda processing the message so that the producer does not need to have any awareness of the processing that the consumer is doing. We use the queue to ensure that producer and consumer can be developed independently.

<br />

#### Isolating failure
---

Decoupling producer and consumer on the Nami data pipeline additionally provides some fault tolerance to the system: should the EC2 instance or post-queue Lambda fail, the queue, or DLQ in the event of extended unavailability, will retain the messages until the system is able to heal.

<br />

### Processing the data
---

<br />

#### Reserved Concurrency for Throttling
---

When the post-queue Lambda function is invoked, it should provide throttling without generating errors while also maximizing concurrency available to the pre-queue Lambda function.  To achieve this, we limited the reserved concurrency of the post-queue Lambda function to allow only 5 concurrent invocations at one time, a limit also recommended in the AWS documentation. This means that from the potential 1,000 concurrent executions available to any given AWS account, only a maximum of 5 will be allocated to the post-queue Lambda. This ensures the pre-queue Lambda function still has a large pool from which to draw, the SQS queue is drained at a steady rate, and the two Lambda functions are never competing for resources.

<br />

#### Batch Size
---

When messages are received from the queue by the post-queue Lambda, it is possible that the function execution can fail, even after a successful write to the database This results in the message not being deleted from the queue. Another successful function execution can then result in duplicate entries in the database. This problem is compounded when there are multiple messages in a batch, because if a batch fails midway, all of the messages from the batch remain in the queue to be processed again. To reduce the impact of this potential issue, we chose to set the maximum batch size that the post-queue Lambda can process to 1. In this case, if a batch size of 1 is written to the data store multiple times, it is only one message that is duplicated.

<br />

#### User-Specific Logic
---

The post-queue Lambda function can contain user-specific logic for data processing and/or sending the webhook message to the user’s other systems at the throttled rate available after the queue. Adding this functionality to the pre-queue Lambda though is less than ideal, because it is best practice to minimize processing here in the interest of a quick response to the provider. TheSetting the reserved concurrency for the post-queue Lambda function provides a controlled environment in which to do any data processing “heavy lifting,” freeing up the pre-queue Lambda to promptly return its response. Nami does provide the user the option to include custom logic for pre-queue lambda to authenticate the webhook provider, however the total amount of code in the pre-queue Lambda is minimized as much as possible to prevent impacting response time.

<br />

#### Reusing Database Connections
---

We enabled the post-queue Lambda function to reuse database connections in order to both reduce the function’s execution duration, as well as efficiently use available database connections. This makes use of the Lambda container’s execution context, creating a closure around the database connection object, the value of which  is accessible to all Lambda executions in the same container. If the connection does not exist, it is created and assigned to a variable in this context space for future Lambda executions to use.

While the function execution duration gains are relatively small, this connection reuse plays a large role in allowing a relatively small EC2 instance to be used with Nami. Each open database connection uses an amount of memory. The EC2 instance is only able to support up to certain number of connections, making the efficient use of these connections a high priority.

<br />

#### Security
---

To ensure that the data store is not accessible from the public internet, the post-queue Lambda function and EC2 instance are both within their own Virtual Private Cloud (VPC) and security group. This restricts all incoming traffic beyond what is needed for the Lambda function to connect to the instance and write to the database.

![security](../assets/security.png)

<br />

#### Handling dropped messages
---

To handle repeated failures of the post-queue Lambda trying to write to MongoDB, a second SQS queue is added to serve as a dead letter queue (DLQ) for the main queue. Any messages that fail to be written to the database 5 times (configurable) will be diverted here for the user to process manually instead of these messages being lost. The DLQ is set to the maximum message retention of 14 days, deliberately giving the user ample time to manually process any failed messages.

<br />

### Storing the data
---

<br />

#### Deploying with Docker
---

Nami deploys a Docker container with MongoDB on an AWS EC2 instance to provide a stable destination for user’s data.  Deploying with Docker, as opposed to direct installation of MongoDB, is well suited to the use of an EC2 instance in our framework because it allows for deployment of the encapsulated container on any system; containerization disassociates the application running inside it from host system configurations.  Once HTTP requests arrive, the Lambda functions can now connect to the EC2 instance and write the webhook data to MongoDB for future retrieval.

<br />

#### Preserving Data during Downtime
---

One challenge with EC2 instances is that any data stored in memory is lost in the event that the instance stops running, or is terminated. To overcome this, Nami’s MongoDB container is pre-configured to store data on a persistent Elastic Block Store (EBS) volume rather than the ephemeral Docker container or EC2 instance itself. A specific filesystem mapping is declared during EC2 provisioning to initiate this change.  This ensures that webhook message data would persist if either of those went offline or were stopped or terminated.

![queue](../assets/queue.png)

<br />

## Implementation Challenges {#implementation-challenges}
---

<br />

### AWS Optimistic Request Object
---

A challenge we faced with deploying all of these AWS components in rapid succession was dependency conflicts where one component relied on the other’s existence in order to be deployed, or a component could not be destroyed when another depended on it. Even using async/await syntax was not enough to overcome the problem of encountering error when attempting to deploy (or destroy) one component when its dependency was not yet resolved.

Errors like this occur because AWS returns an optimistic Response Request Object with a successful response when creating or deleting resources via the AWS SDK. Despite awaiting each SDK call, the next asynchronous operation is performed upon receipt of an optimistic response, not when the component is actually prepared to accept the next operation.

In development, this latency was periodically throwing errors, both when deploying dependent resources and when destroying them. For example, after calling the `nami destroy` command, which terminates the EC2 instance associated with a resource, we received an error when trying to destroy the security group associated with it because the instance had not actually been terminated yet.

![optimistic_response](../assets/optimistic_response.png)

To overcome this, we implemented a simple while loop which used the AWS SDK to check the instance’s status code and only return from the function call after receiving the appropriate terminated code.

<br />

### Automated Provisioning
---

The use of a Docker container on an EC2 instance presented a few challenges. How do we programmatically install the Docker container with appropriate port and volume mappings and database / collection creation when the EC2 instance is launched?

Nami automatically installs, configures, and runs both Docker and MongoDB by passing in a shell script that is automatically run when the EC2 instance is instantiated. This shell script performs the following:

- updates package database with apt-get
- installs Docker and the Docker CLI
- downloads and runs the MongoDB Docker image
- configures the MongoDB container to write to the EBS volume
- publishes the same port MongoDB uses to the Ubuntu host

Another question faced with running Docker on EC2 was - what happens if an EC2 instance were to temporarily stop running? Docker containers need to be `run` in order to be used, and they stop running when their host system stops running. We needed a way to ensure that the container would always be available and running as long as the EC2 instance was on. Docker allows us to configure a restart policy per container: `--restart=always` ensures that our container will always be up and running when the EC2 instance is running.

<br />

## Message Ordering and Duplication {#message-ordering-and-duplication}
---

Using a message queue in an EDA introduces a handful of variables that needs to be considered to set expectations for how the data is delivered to and ultimately stored by the system.

<br />

### Ordering
---

Ordering of messages can be important if event data that webhook messages contain triggers state changes. The order in which messages arrive in the database cannot be guaranteed for multiple reasons.

Send failures, variable latencies, and implementation details can result in webhook data to be received out of order (8). HTTP requests can also be refused for a variety of reasons. If a webhook provider sends a request that the webhook consumer rejects, typically the provider will store the message and try again later, often multiple times per day until the message is finally accepted. This message, however, will now be out of order compared to other messages sent before the first message was finally accepted.

![out_of_order](../assets/out_of_order.png)

Also within the framework itself, the SQS message queue does not guarantee ordering. Messages can be removed from the queue in a different order than they were received. Additionally, retry attempts can contribute to messages being consumed out of order and further exacerbate the problem.

The user will need to sort webhook messages by timestamp or unique event id included in the payload by the webhook provider if ordering is a concern.

<br />

### Duplication
---

A standard SQS queue deployed by Nami guarantees at least once message delivery. The consequence of this is that the queue could deliver the same message more than once, and the post-queue Lambda could process duplicate messages. Filtering messages by timestamp, or unique event id sent by the producer can help users identify duplicate webhook messages. Alternatively, the user’s application logic itself can be made idempotent so that it can handle duplicate messages without affecting the state of their system beyond the first receipt of the message.

<br />

## Load Testing
---

With an automatically scaling system, how it performs requires attention given the data pipeline is built across multiple components whose capacity to scale without error depends on a number of factors. Simulating bursty traffic is difficult, but a quick and dirty test should help identify possible bottlenecks and breakpoints for a given load and set operational bounds on our system.

![load_testing](../assets/load_testing.png)

The primary feature of the architecture is its scalability, so requests per second (RPS)  should give a good indication as to how the deployment scales. We used Apache bench, with runs scheduled simultaneously from multiple EC2 instances, to send a number of HTTP POST requests to a Nami API endpoint. The tests then returned indicators for failed requests and the number of requests made per second. The system was able to respond successfully within tolerable response times, handling approximately 4,000 RPS with no errors generated, and up to 4,800 RPS with only 3 errors generated during this test.

<br />

## Future Plans {#future-plans}
---

While Nami works as expected using the commands described above, there are several additional directions we would like to explore with the Nami framework.

<br />

### Greater customization options
---

While the user can currently customize any of the resources deployed using Nami via the AWS web console or the AWS CLI, we would like to expand Nami so that users can pass in flags during the `nami deploy <name>` command to customize their deployment. Options we would like to provide the user include allowing them to configure:

- an EC2 instance type
- an EBS volume size
- a custom memory/timeout for Lambdas
- custom error handling/response codes
- a custom queue message retention period

<br />

### Monitoring alerts
---

Currently the user needs to monitor the infrastructure set up by Nami to check if there are any errors or messages in the DLQ. We would like to implement CloudWatch alarms that would direct the user’s attention to any abnormal events in the system.

<br />

### Support for GET method
---

Currently, Nami only supports the `POST` HTTP method for incoming webhooks. While `POST` is most common, the `GET` method is also used by some producers for sending webhook requests, with payload data being sent as query parameters. We would like to add support for this in the future.

<br />

## About Us {#about-us}
---

<!-- <div id="team">
  <p>
    Our team of three software engineers collaborated remotely across North America and Europe to build Nami. Feel free to reach out to us if you have any questions about Nami or would like to discuss any of the topics mentioned in our write up.
  </p>

  <ul>
    <li class="individual">
      <a href="https://wendykuhn.io/" target="_blank">
        <img src="../assets/wendy.png" alt="Wendy Kuhn"/>
      </a>
      <h3>Wendy Kuhn</h3>
      <p>Austin, TX</p>
    </li>
    <li class="individual">
      <a href="https://sachinmc.github.io/" target="_blank">
        <img src="../assets/sachin.png" alt="Sachin Chandy"/>
      </a>
      <h3>Sachin Chandy</h3>
      <p>London, UK</p>
    </li>
    <li class="individual">
      <a href="https://nickmiller.io" target="_blank">
        <img src="../assets/nick.jpg" alt="Nick Miller"/>
      </a>
      <h3>Nick Miller</h3>
      <p>Los Angeles, CA</p>
    </li>
  </ul>
</div> -->

<br />

## References {#references}
---

1. https://www.amazon.com/Scalability-Startup-Engineers-Artur-Ejsmont/dp/0071843655
2. https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321
3. https://www.manning.com/books/aws-lambda-in-action
4. https://www.jeremydaly.com/how-to-use-sns-and-sqs-to-distribute-and-throttle-events/
5. https://web.archive.org/web/20180120002912/http://www.progrium.com/blog/2007/05/03/web-hooks-to-revolutionize-the-web/
6. https://nordicapis.com/5-protocols-for-event-driven-api-architectures/
7. https://launchschool.com/books/working_with_apis/read
8. https://brandur.org/webhooks
9. https://en.wikipedia.org/wiki/Denial-of-service_attack
10. https://martinfowler.com/articles/serverless.html
11. https://aws.amazon.com/api-gateway/
12. https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html
13. https://docs.aws.amazon.com/lambda/latest/dg/scaling.html
14. https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/
15. https://winterwindsoftware.com/scaling-lambdas-inside-vpc/
16. https://blog.codebarrel.io/new-monitor-your-service-limits-automation-for-jira-performance-update-32525ec02711
17. https://rewind.io/blog/handle-shopify-webhooks-without-a-server/
18. https://www.slideshare.net/AmazonWebServices/best-practices-for-using-aws-lambda-with-rdsrdbms-solutions-srv320
19. https://en.wikipedia.org/wiki/Docker_(software)
20. https://en.wikipedia.org/wiki/Webhook
21. https://www.manning.com/books/serverless-architectures-on-aws
